{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSxrcGn+lxpgHhTUdGTLoB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjcoursera/TensorFlow/blob/main/simple_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X9r7Y96QnX-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Make numpy printouts easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGwE2pyfQu_h",
        "outputId": "454f423a-911f-4a00-9b59-341c304f7856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtQZIMd9Q2kY",
        "outputId": "8768d713-67d3-4e96-a3c5-0743a13a7953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units = 1, input_shape=[1]))\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "xs = np.array([-1, 0,1,2,3,4], dtype=float)\n",
        "ys = np.array([-3,-1,1,3,5,7], dtype=float)\n",
        "model.fit(xs,ys, epochs = 50)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.9400\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 11.2017\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0424\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3389\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9941\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9315\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 918us/step - loss: 4.0911\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4255\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8976\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.4782\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1441\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8773\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6634\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4913\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3522\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2391\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1465\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0701\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0065\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9532\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9078\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8690\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8352\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8055\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7791\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 947us/step - loss: 0.7553\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7337\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 931us/step - loss: 0.7138\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6954\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6781\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6619\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6464\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6317\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6176\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6040\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5909\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5782\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5659\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5539\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5423\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5309\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5199\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5091\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4985\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 947us/step - loss: 0.4882\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4781\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4682\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4586\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4491\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc420f63780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R3pguUV5mSO",
        "outputId": "900bd981-c2d0-47ab-894f-b9737ceeecca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.predict([10.0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17.029]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDk1mHn5sEo",
        "outputId": "1f485f07-47dc-4660-c583-fb479713d692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.predict([20.0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[34.189]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNc7mb7l5Qea"
      },
      "source": [
        "def house_model(y_new):\n",
        "    xs = np.array([1.0,2.0, 3.0, 4.0], dtype = float)# Your Code Here#\n",
        "    ys = np.array([1.0,1.5,2.0,2.5], dtype = float)# Your Code Here#\n",
        "    model = keras.Sequential([keras.layers.Dense(units = 1, input_shape=[1])])# Your Code Here#\n",
        "    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
        "    model.fit(xs,ys, epochs = 50)\n",
        "    return model.predict(y_new)[0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp6CrrsX5TJE",
        "outputId": "e70f0ce1-e38d-4fb1-9ac7-453ed4ca2f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prediction = house_model([7.0])\n",
        "print(prediction)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 14.1254\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8016\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8015\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7197\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2752\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2729\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5775\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 838us/step - loss: 1.0949\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7600\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5277\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 962us/step - loss: 0.3665\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2546\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1770\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 819us/step - loss: 0.1231\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0857\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0598\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 983us/step - loss: 0.0418\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 871us/step - loss: 0.0293\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0206\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0146\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 954us/step - loss: 0.0075\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0055\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0041\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0031\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 943us/step - loss: 0.0020\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 835us/step - loss: 0.0013\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 847us/step - loss: 0.0010\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8542e-04\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5501e-04\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 944us/step - loss: 9.3228e-04\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 806us/step - loss: 9.1490e-04\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0123e-04\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.9016e-04\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8089e-04\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7289e-04\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6577e-04\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 769us/step - loss: 8.5927e-04\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5322e-04\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4749e-04\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4198e-04\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3664e-04\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3142e-04\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 795us/step - loss: 8.2631e-04\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.2126e-04\n",
            "[4.096]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ3txNkKvvUm",
        "outputId": "66a142b7-8956-4d58-e149-eb9d753e3576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4794\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3589\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3226\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2988\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc41c75a518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glg3_fWBwC29",
        "outputId": "39366d02-2283-4fe6-ad07-588314954f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()\n",
        "training_images =  training_images/255.0\n",
        "test_images =  test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(units = 256, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(units = 10, activation='softmax')\n",
        "\n",
        "]) \n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy')\n",
        "model.fit(x=training_images, y=training_labels, epochs=5,callbacks=[callbacks])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2285\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc41df05d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M-f1JlBZEsZ",
        "outputId": "364cee0c-1475-495b-8552-97d00c6d5130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def train_mnist():\n",
        "    # Please write your code only where you are indicated.\n",
        "    # please do not remove # model fitting inline comments.\n",
        "\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs = {}):\n",
        "            if(logs.get('accuracy')>0.99):\n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "                self.model.stop_training = True\n",
        "    \n",
        "    callbacks = myCallback()\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "    # YOUR CODE SHOULD START HERE\n",
        "    x_train =  x_train/255.0\n",
        "    x_test =  x_test/255.0\n",
        "    # YOUR CODE SHOULD END HERE\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE SHOULD START HERE\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units = 256, activation='relu'),\n",
        "        tf.keras.layers.Dense(units = 10, activation= 'softmax')\n",
        "        # YOUR CODE SHOULD END HERE\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(x=x_train, y=y_train, # YOUR CODE SHOULD START HERE\n",
        "              epochs=8,callbacks=[callbacks]\n",
        "                # YOUR CODE SHOULD END HERE\n",
        "    )\n",
        "    # model fitting\n",
        "    return history.epoch, history.history['accuracy'][-1]\n",
        "train_mnist()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2257 - accuracy: 0.9356\n",
            "Epoch 2/8\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0933 - accuracy: 0.9719\n",
            "Epoch 3/8\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0611 - accuracy: 0.9813\n",
            "Epoch 4/8\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0454 - accuracy: 0.9858\n",
            "Epoch 5/8\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0338 - accuracy: 0.9894\n",
            "Epoch 6/8\n",
            "1854/1875 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9917\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0250 - accuracy: 0.9917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5], 0.991683304309845)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n5eATdtwraW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}